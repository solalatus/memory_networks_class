{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "memory_networks.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1uMmLWO-FvkXcmGuM5K2sOPXvh-Yhgaoq",
          "timestamp": 1525421035094
        }
      ],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "cfnCGP4chBzY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Memory Networks"
      ]
    },
    {
      "metadata": {
        "id": "oUNIxEB3A1xa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Gated RNN memóriaproblémák\n",
        "\n",
        "### Viszonylag kicsi \"munkamemória\"\n",
        "\n",
        "Az LSTM és variánsainak memóriája (a hidden state mérete) meglehetősen kicsi\n",
        "\n",
        "<img src=\"http://drive.google.com/uc?export=view&id=1-LbAhO8U_sfr5ipSaPTEm_0niPxS39u8\" width=\"700px\">\n",
        "\n",
        "még nagy, mondjuk 2000-es réteghosszokkal és 64 bites lebegőpontos számokkal kalkulálva is csak kb. 128kbit = 16kB-ról beszélhetünk, ami már a PC-k őskorában sem számított soknak...\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/af/Commodore_16_002a.png/1920px-Commodore_16_002a.png\" width=\"700px\">\n"
      ]
    },
    {
      "metadata": {
        "id": "wGLaBXz3Lu2S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### A súlyok tárigénye\n",
        "\n",
        "A súlyok száma viszont négyzetesen függ a memória méretétől, mivel a felejtő stb. kapuk sűrű rétegek.\n",
        "\n",
        "Ha a rejtett állapot mérete $h$, akkor a kapuk súlyainak száma LSTM esetén $8 h^2$, vagyis a 2000-es példánál maradva\n",
        "\n",
        "32 millió súlyról beszélhetünk, aminek a tárigénye már (szintén 64 bites számokkal számolva) kb. 256MB (!!).\n",
        "\n",
        "#### Külső memória\n",
        "\n",
        "Az alapkérdés tehát: hogyan tudnánk úgy növelni a munkamemóriát, hogy eközben a súlyok száma nem növekszik?"
      ]
    },
    {
      "metadata": {
        "id": "w2BmxuLYXLiw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Attention a seq2seq modellekben (emlékeztető)\n",
        "\n",
        "Alap seq2seq architektúra:\n",
        "\n",
        "<img src=\"http://suriyadeepan.github.io/img/seq2seq/seq2seq2.png\">\n",
        "\n",
        "\n",
        "A seq2seq feladatok jelentős része nem \"holisztikus\" abban az értelemben, hogy az output sorozat előállításának különböző fázisaiban az inputsorozat más más részei fontosak, más-más elemekre célszerű \"figyelni\", mások akár többé-kevésbé irrelevánsak is lehetnek. Ennek ellenére az alap decoder-encoder modell csak a teljes sorozatot reprezentáló, egyetlen végső rejtett állapot alapján dolgozik, nem fér hozzá az encoder korábbi rejtett állapotainak éppen releváns részéhez. Korábban bizonyos trükökkel próbálták \"erősíteni\" a korábbi állapotok hatását, pl. megfordítva adták be az inputot, vagy többször,de az igazi megoldásnak az ú.n. attention mechanizmus látszik:\n",
        "\n",
        "<img src=\"https://cdn-images-1.medium.com/max/1600/0*SY3nv8-J6qX1GUxk.png\">\n",
        "\n",
        "Vagyis a dekóder minden egyes lépésben megkapja az előző rejtett állapot és kimenet mellett az enkóder összes rejtett állapotának egy _súlyozott átlagát_ is, mint kontextust. A kontextus a dekóder $i$. lépésében:\n",
        "\n",
        "$$ c_i = \\sum_{j=1}^{T}\\alpha_{ij}h_j$$\n",
        "\n",
        "ahol minden $h_k$ enkóder rejtett állapotra egy párhuzamosan tanított $A$ feed-forward háló ad egy \n",
        "\n",
        "$$e_{ik} = A(h_k, s_{i-1})$$ \n",
        "\n",
        "súlyt (a $h_k$ enkóder állapottal és $s_{i-1}$-gyel, vagyis a dekóder előző rejtett állapotával, mint inputtal), és ezekből az $\\alpha_{ij}$ súlyok softmaxszal állnak elő:\n",
        "\n",
        "$$\\alpha_{ij} = \\frac{\\exp e_{ij}}{\\sum_{k=1}^{T}\\exp e_{ik}}$$\n",
        "\n",
        "\n",
        "A klasszikus cikk az attention-mechanizmusról: [Bahdanau et al: \"Neural machine translation by jointly learning to align and translate.\" (2014).](https://arxiv.org/pdf/1409.0473.pdf)"
      ]
    },
    {
      "metadata": {
        "id": "lSJN3Wv9ESZy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Memory Networks\n",
        "\n",
        "[Weston et al. (Facebook AI Research, 2014): Memory Networks](https://arxiv.org/pdf/1410.3916.pdf)\n",
        "\n",
        "### Absztrakt architektúra: IGOR\n",
        "\n",
        "- __Input__: Belső feature reprezentációkká alakítja a nyers inputot.\n",
        "- __Generalizáció__: Az input alapján frissíti a memóriát, tipikusan tömöríteni/generalizálni próbál.\n",
        "- __Output__: Új outputot generál (a feature reprezentációs térben) az input és az aktuális memóriaállapot alapján.\n",
        "- __Response__: Az outputot a megkívánt külső formátumra hozza.\n",
        "\n",
        "### A modulok kicsit részletesebben\n",
        "#### Input\n",
        "NLP alkalmazások esetében itt történhet a preprocessing és az embedding is.\n",
        "#### Generalizáció\n",
        "A legegyszerűbb megoldás egyszerűen eltárolja az aktuális input belső reprezentációját egy adott, az $x$ nyers inputtól függő memóriában:\n",
        "\n",
        "$$m_{H(x)} = I(x) $$\n",
        "\n",
        "ahol a $H(.)$ függvény határozza meg a megfelelő memóriát.\n",
        "\n",
        "#### Output és response\n",
        "- Tipikusan az output olvassa és állítja össze a releváns memóriákat (ez egyfajta reasoning-et is jelenthet)\n",
        "- Az output alapján a response adja a végső választ, lehet pl. egy RNN dekóder."
      ]
    },
    {
      "metadata": {
        "id": "lfE3XGpSKnKg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Neural Memory Network Implementations: MEMNN\n",
        "\n",
        "Egyszerű baseline megvalósítás: question answering (a memóriában tárolt tények alapján). Az input mindig egy mondat: vagy\n",
        "\n",
        "- egy tényt rögzít, vagy \n",
        "- egy megválaszolandó kérdést tesz fel.\n",
        "\n",
        "##### Generalizáció/tárolás\n",
        "\n",
        "Egyszerűen mindig eltároljuk egy új slotban bejövő tényeket változtatás nélkül.\n",
        "\n",
        "##### Output modul\n",
        "\n",
        "$k$ számú releváns memóriatartalmat keres ki egy $S_o$ scoring függvény segítségével. Konkrétan $k=2$ esetén\n",
        "\n",
        "$$o_1 = \\mathrm{argmax}_{i=1\\dots N}~ S_o(x, \\mathbf{m}_i) $$\n",
        "\n",
        "$$o_2 = \\mathrm{argmax}_{i=1\\dots N}~ S_o([x, \\mathbf{m}_{o_1}], \\mathbf{m}_i) $$\n",
        "\n",
        "A végső output $[x, \\mathbf{m}_{o_1}, \\mathbf{m}_{o_2}]$, ez a response modul inputja.\n",
        "\n",
        "##### Response\n",
        "\n",
        "A legegyszerűbb esetben ez egyetlen szót generálunk válaszként, és ezt egy újabb scoring függvénnyel tesszük:\n",
        "\n",
        "$$r = \\mathrm{argmax}_{w \\in W} ~ S_r([x, \\mathbf{m}_{o_1}, \\mathbf{m}_{o_2}], w) $$\n",
        "\n",
        "##### Scoring függvények\n",
        "\n",
        "Mind $S_o$, mind $S_r$ formája\n",
        "\n",
        "$$S(x, y) = \\phi_x(x)^\\top U^\\top U \\phi_y(y)$$\n",
        "\n",
        "ahol a $\\phi$-k a szövegeket egy $D$ dimenziós feature space-be képzik (a legegyszerűbb modell bag-of-words reprezentációkat használt) az U-k pedig embedding mátrixok, tehát végeredményben a sűrű reprezentációk vetületét használjuk.\n",
        "\n",
        "##### Training\n",
        "\n",
        "A két embedding mátrixot, $U_o$-t és $U_r$-t próbáljuk optimalizálni SGD-vel, de nem end2end, hanem __strongly supervised__ módon, mivel a tanulóadat megjelöli a két releváns adatot is.\n",
        "\n",
        "##### Javított modellek\n",
        "\n",
        "- __Memória hashing:__ Ha túl sok a memóriában tárolt tény, akkor nagyon drága az összes tényt score-olni, ezért bucketekbe hasheljük a tényeket, és csak a kérdésnek megfelelő bucketekben keresünk. Pl. minden szóhoz tartozhat egy bucket, ekkor csak a kérdéssel közös szót tartalmazó tényeket vizsgáljuk. (Fejlettebb változat: clusterezzük a wordembeddingeket, és az egy-egy clusterhez tartozó szavakat tart. tények kerülnek egy bucketba).\n",
        "\n",
        "- __Beérkezési idő:__ NLP feladatokhoz fontos reprezentálni azt is, hogy milyen sorrendben jöttek be az inputok, amelyeket score-olunk. A  $\\phi$ featurereprezentációt kiegészítjük ilyen adatokkal.\n",
        "\n",
        "- __Új szavak__: Ezeket a tipikus környezetükkel (BOW) modellezhetjük, ezt is hozzáadjuk a feature-ökhöz.\n",
        "\n",
        "- __Output generálás__: teljes mondat RNN dekóderrel egyetlen szó helyett."
      ]
    },
    {
      "metadata": {
        "id": "dk5zBfhhefg8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Eredmények\n",
        "\n",
        "- __Large scale QA__ Keresés 14M memóriában tárolt (subject, relation, object) triplet között (pl. milne authored winnie-the-pooh) -- term. nyelvű kérdés alapján, pl. \"Who is pooh's creator?\"\n",
        "\n",
        "> \"The results show that MemNNs are a viable approach for large scale QA in\n",
        "terms of performance.\"\n",
        "\n",
        "- __Simulated World QA__ \n",
        "\n",
        "Kérdések megválaszolása egyszerű sztorik alapján.\n",
        "\n",
        ">we also built a simple simulation of 4 characters, 3 objects and 5 rooms – with characters moving around, picking up and dropping objects. The actions are transcribed into text using a simple automated grammar, and labeled questions are generated in a similar way.\n",
        "\n",
        "<img src=\"http://drive.google.com/uc?export=view&id=1oxe_-Wm4s4K-Ax880NCu4Z_lK-PFnriH\">\n",
        "\n",
        "<img src=\"http://drive.google.com/uc?export=view&id=1BtY9jKwtt3xr4NS9huadwCTllP-GQCkp\" width=\"700px\">\n",
        "\n",
        "(Nehézség: Max. az utolsó előtti hányadik mondatban szerepelt utoljára a kérdezett tárgy. Actor vs actor + object kísérlet: az elsőben csak a \"go\" cselekvés volt megengedett, utóbbiban \"get\" és \"drop\" is)"
      ]
    },
    {
      "metadata": {
        "id": "96xAgE4DKqKM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://memegenerator.net/img/instances/64071735/where-is-the-catch.jpg\" width=\"400px\"> \n",
        "\n",
        "### Térjünk vissza a tréninghez egy pillanatra..."
      ]
    },
    {
      "metadata": {
        "id": "ggHJ_eR7Tx8g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ha kicsit részletesebben megnézzük, a következő loss-t használták:\n",
        "\n",
        "<img src=\"http://drive.google.com/uc?export=view&id=1ZIjx9V0hmSpP1FfLAqNS_Wx399LeDzrp\" width=\"700px\">\n",
        "\n",
        "Vagyis a loss egy konkrét példára az összes rossz jelöltre a jó jelölt score-jától való távolságnak a margintól való eltérése.\n",
        "Rögzített jó jelöltek ($\\mathbf{m_{o_1}, m_{o_1}}$) esetén ez (majdnem mindenütt) differenciálható $U_O$ és $U_R$ szerint, de ha ezek nem adottak, hanem a\n",
        "\n",
        "$$o_1 = \\mathrm{argmax}_{i=1\\dots N}~ S_o(x, \\mathbf{m}_i) $$\n",
        "\n",
        "$$o_2 = \\mathrm{argmax}_{i=1\\dots N}~ S_o([x, \\mathbf{m}_{o_1}], \\mathbf{m}_i) $$\n",
        "\n",
        "egyenleteknek megfelelően szerepeltetjük őket a loss-ban, akkor elveszítjük a differenciálhatóságot, mert a maximális pontszámú memória változásánál \"ugrik\" a függvény $\\Rightarrow$ __a rendszer nem trénelhető end-to-end módon__. Ezen a problémán segít a...\n"
      ]
    },
    {
      "metadata": {
        "id": "KEaSfkbmLzgg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## End-To-End Memory Networks (MemN2N)\n",
        "\n",
        "[Sukhbaatar et al. (NYU,  Facebook AI Research, 2015): End-To-End Memory Networks](http://papers.nips.cc/paper/5846-end-to-end-memory-networks.pdf)\n",
        "\n",
        "Koncepció: Adjuk egy folytonos, end-to-end változatát a Memory Network koncepciónak!\n",
        "\n",
        "### Alapfeladat: QA\n",
        "\n",
        "Megegyezik az eredeti MN alapfeladattal:\n",
        "\n",
        "- Beérkezik input \"tények\" egy $x_1,\\dots x_n$ sorozata és egy $q$ kérdés\n",
        "- adjunk vissza egy $a$ választ a kérdésre.\n",
        "\n",
        "A rendelkezésre álló dataset-ben csak a fenti adatok vannak megadva, tehát nincsenek megjelölve a releváns tények.\n",
        "\n",
        "### Baseline modell\n",
        "\n",
        "A memória egy rögzített hosszúságú buffer, az inputot ebben tároljuk. Két embedding mátrixot ($A$, $B$) használva mind a tényeket/memóriatartalmakat, mind a kérdést sűrű vektorreprezentációkká alakítjuk, és utána egyszerű koszinusztávolsággal pontozzuk az összes tény/memóriatartalom relevanciáját. Erre softmax-ot alkalmazva kapunk egy relevanciaeloszlást, aminek értéke minden $i$ memóriaindexre\n",
        "\n",
        "$$p_i = \\mathrm{Softmax}(u^\\top m_i)$$\n",
        "\n",
        "ahol $u$ a kérdés embedding vektora. \n",
        "\n",
        "Az $x_i$ tényekhez egy harmadik, $C$ embeddinggel $c_i$ outputvektorokat is rendelünk, és a response vektor egyszerűen ezek $p$ szerint súlyozott átlaga lesz:\n",
        "\n",
        "$$o = \\sum_{i}p_i c_i$$\n",
        "\n",
        "A legegyszerűbb modell, amely egyszerűen egy egyszavas választ generál innen egyetlen feedforward réteggel és softmaxszal megy tovább:\n",
        "\n",
        "$$a = \\mathrm{Softmax}(W(o + u))$$\n",
        "\n",
        "<img src=\"http://drive.google.com/uc?export=view&id=1O_toD6rZ-oJEnPjgXjcHkaAXGYjmZkWX\" width=\"800px\">"
      ]
    },
    {
      "metadata": {
        "id": "R7U2oUKuq_0-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Többrétegű architektúra\n",
        "\n",
        "Minden rétegnek saját $A$ és $C$ embedding mátrixa van, és az első utáni rétegeket úgy helyezzük egymásra, hogy a $k + 1$. réteg egyedi vektorbemenete mindig az előző rétegre adott output:\n",
        "\n",
        "$$u^{k+1} = u^k + o^k$$\n",
        "\n",
        "\n",
        "<img src=\"http://drive.google.com/uc?export=view&id=1vq8UHIRn6ClmyLYWSAJiVzCNIoREmDQH\" width=\"450px\">"
      ]
    },
    {
      "metadata": {
        "id": "PkDH22it2gR8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Kipróbált megoldások az $A$ és $C$ rétegek egymáshoz kapcsolására összesen $K$ réteg esetén:\n",
        "\n",
        "- minden $k$-ra $A^{k+1}= C^k$ és $A^1 = B$, $W = C^K$\n",
        "\n",
        "- RNN-szerű megoldás: minden $A_i$ és $C_i$ megegyezik -- ez lényegében egy speciális RNN architektúrának felel meg, amit fix lépésszámmal futtatunk.\n",
        "\n",
        "#### Mondatinput embedding megoldások\n",
        "- BOW: Szószintű embeddinget alkalmazunk, és a mondatvektor egyszerűen a mondat szóvektorainak összege (szórendfüggetlen).\n",
        "- Positional Encoding (PE): Mondatpozíciótól függően súlyozzuk a szóvektorokat az összegben (szórendfüggő)."
      ]
    },
    {
      "metadata": {
        "id": "YS1X448R_ehG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Eredmények\n",
        "\n",
        "#### A bAbI dataset\n",
        "\n",
        "bAbI feladatok: szintetikus, szimulációval előállított QA \"játék\" dataset\n",
        "\n",
        "([Weston et al (Facebook AI Research, 2016): Towards ai-complete question answering: A set of prerequisite toy tasks.](https://arxiv.org/pdf/1502.05698.pdf)):\n",
        "\n",
        ">All of the tasks are noiseless and a human able to read that language can potentially achieve 100%\n",
        "accuracy. We tried to choose tasks that are natural to a human: they are based on simple usual situations and no background in areas such as formal semantics, machine learning, logic or knowledge\n",
        "representation is required for an adult to solve them.\n",
        "\n",
        ">The data itself is produced using a simple simulation of characters and objects moving around and\n",
        "interacting in locations, described in Section 4.  The simulation allows us to generate data in many\n",
        "different scenarios where the true labels are known by grounding to the simulation.\n",
        "\n",
        "Komponensek:\n",
        "\n",
        "- \"entitások\"\n",
        "  - helyek\n",
        "  - tárgyak\n",
        "  - személyek\n",
        "- állapotok\n",
        "  - abszolút/relatív hely\n",
        "  - mentális állapot\n",
        "- tulajdonságok\n",
        "  - méret\n",
        "  - szín\n",
        "- cselekedetek:\n",
        "  - go _location_, get _object_, get _object1_ from _object2_, put _object1_ in/on _object2_, give _object_ to\n",
        "_actor_, drop _object_, set _entitity_ _state_, look, inventory and examine _object_.\n",
        "\n",
        "\"For each task, we describe it by giving a small sample of the dataset including statements, questions and the true\n",
        "labels (in red) in Tables 1 and 2.\"\n",
        "\n",
        "<img src=\"http://drive.google.com/uc?export=view&id=1zwM3eG-QuTkcyWWFzgius2r_xCMyTPOo\" width=\"700px\">\n",
        "\n",
        "<img src=\"http://drive.google.com/uc?export=view&id=1GpyNrRy9B294D01SpspKX9mpxVFqp0D5\" width=\"700px\">\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "nqkb5-hLL3DA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### N2N MN eredmények a bAbI datasetten\n",
        "\n",
        "\n",
        "- Az N2N MN jelentősen megverte a baseline LSTM-et (51,3 vs 12,4% mean error)\n",
        "- Az N2N MN legerősebb beállításokkal csak összemérhető az erősen felügyelt MN-nel (12,4 vs 6,7% mean error)"
      ]
    },
    {
      "metadata": {
        "id": "N7sP2bKphJHI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Dynamic Memory Networks (DMN)\n",
        "\n",
        "[Kumar et al. (2016): Ask me Anything: Dynamic Memory Networks for Natural Language Processing](http://proceedings.mlr.press/v48/kumar16.pdf)\n",
        "\n",
        "__Célkitűzés:__ Általános kérdésmegválaszoló framework.\n",
        "\n",
        "A legtöbb NLP-s feladat átfogalmazható kérdésmegválaszolási feladattá:\n",
        "\n",
        "#### Klasszikus kérdésmegválaszolás:\n",
        "_Bemenő információk (tények):_\n",
        "- Jane went to the hallway.\n",
        "- Mary walked to the bathroom.\n",
        "- Sandra went to the garden.\n",
        "- Daniel went back to the garden.\n",
        "- Sandra took the milk there.\n",
        "\n",
        "_Kérdés:_ Where is the milk?\n",
        "\n",
        "_Válasz:_ garden\n",
        "\n",
        "#### Sentiment analysis/POS tagging\n",
        "\n",
        "_Bemenő információ_: It started boring, but then it got interesting.\n",
        "\n",
        "_Kérdés_: What’s the sentiment?/What are the POS tags?\n",
        "\n",
        "_Válasz_: positive/PRP VBD JJ , CC RB PRP VBD JJ"
      ]
    },
    {
      "metadata": {
        "id": "qz5jUybTui5U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Moduláris architektúra\n",
        "\n",
        "<img src=\"http://drive.google.com/uc?export=view&id=1rJKn4sHmtcTzipr91t4macxy9jpD7pC2\" width=\"500px\">"
      ]
    },
    {
      "metadata": {
        "id": "KPPGQra3yYHC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- __Input modul:__ A bemenő szöveget, amely lehet egy mondat, de akár több dokumentum is, sűrű vektorreprezentációk sorozatává alakítja.\n",
        "\n",
        "- __Kérdés modul:__ A kérdést alakítja egyetlen sűrű vektorrá.\n",
        "\n",
        "- __Epizodikus memória:__ Egy attention mechanizmus segítségével előállít egy \"releváns tények\" vektorreprezentációt.\n",
        "\n",
        "- __Válasz modul:__ Előállítja a választ az epizodikus memória és a kérdésvektor alapján."
      ]
    },
    {
      "metadata": {
        "id": "hueU76Tx8zbA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### A modulok részletesen\n",
        "\n",
        "#### Input modul\n",
        "\n",
        "- A  tokenizált inputot először egy (a kérdésmodullal közös) word embedding segítségével szóvektorsorozattá alakítjuk\n",
        "- A szóvektorsorozatot egy RNN (GRU/LSTM) hidden-state vektorok sorozatává alakítja\n",
        "  - ha egy mondat a bemenet (pl. POS tagging), akkor minden tokenhez tartozik egy hidden state\n",
        "  - ha több, akkor a mondatok végén fennálló hidden state-ekből áll a reprezentáció\n",
        "\n",
        "#### Kérdés modul\n",
        "\n",
        "- A felépítése megegyezik az input modullal, de az output egyszerűen a kérdés feldolgozása végén adódó hidden state.\n"
      ]
    },
    {
      "metadata": {
        "id": "RtOSkEtCC-nI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Epizodikus memória\n",
        "<img src=\"http://drive.google.com/uc?export=view&id=1-1yrOVyHXZiqwHb4I-kdGXOWtlTe4C7b\">\n",
        "\n",
        "Az epizodikus memória egy vagy több menetben összegzi az összes input \"tényt\" úgy, hogy egy attention mechanizmus minden tényhez egy súlyt rendel.\n"
      ]
    },
    {
      "metadata": {
        "id": "f_3MO2eFMDPI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Az attention súlyok kiszámítása\n",
        "\n",
        "A súlyokat egy feed-forward háló számítja ki a következő paraméterek alapján:\n",
        "\n",
        "- $c$: a tényvektor, amihez a súlyt keressük\n",
        "- $m$: a memória állapota az előző menet végén\n",
        "- $q$: a kérdésvektor\n",
        "\n",
        "ezekből először előállítjuk a köv. $z(c, m, q)$ hasonlósági feature vektort:\n",
        "\n",
        "$$z(c, m, q) = [c, m, q, c\\circ q, c\\circ m, |c-q|, |c-m|, c^\\top W^{(b)}q,c^\\top W^{(b)}m]$$\n",
        "\n",
        "majd ezzel az inputtal a feed-forward hálóval kiszámítjuk a súlyt:\n",
        "\n",
        "$$G(c, m, q)=\\sigma(W^{(2)}\\tanh(W^{(1)}z(c, m,q) + b^{(1)}) + b^{(2)})$$\n",
        "\n",
        "Vannak datasettek, amelyek megadják a tényrelevanciát is (pl. [Facebook bAbI](https://research.fb.com/downloads/babi/)), ott ez a komponens supervised módon cross-entropy losssal tanítható, egyébként marad az end-to-end.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "3iHXp3j5MH8W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### A memória update menete és vége\n",
        "\n",
        "Az $i.$ frissítés során az összes tényen végighalad egy RNN (konkrétan GRU) a köv. belső állapot egyenlettel:\n",
        "\n",
        "$$h_t^i = g^i_t RNN(c_t, h^i_{t-1}) + (1-g^i_t)h^i_{t-1}$$\n",
        "\n",
        "Az RNN kezdő belső állapota a $q$ kérdésvektor, és az $i.$ memóriaállapot nem más, mint az RNN sorozatvégi belső/rejtett állapota.\n",
        "\n",
        "_Megállás_: Az input végéhez adunk egy speciális STOP szimbólumot, és ha az attention ezt választja, akkor megállunk. (Ha nincs supervised adat a megállásról, akkor egyszerűen egy fix maximum menetszámot használunk.)\n"
      ]
    },
    {
      "metadata": {
        "id": "EdJN9PFHRl3A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Válasz modul\n",
        "\n",
        "A válaszmodul feladatfüggően vagy minden memórialépésnél (pl. POS-tagging), vagy egy teljes memóriafrissítés végén aktiválódik.\n",
        "\n",
        "Itt is egy RNN-t (GRU)-t használunk, amelyet a $q$ kérdésvektorral inicializálunk, és kimenete minden $t$ time stepnél az $a_t$ belső állapotból\n",
        "\n",
        "$$y_t = \\mathrm{softmax}(W^{(a)}a_t)$$\n",
        "\n",
        "belső állapota pedig\n",
        "\n",
        "$$a_t =RNN([y_{t-1}, q], a_{t-1})$$\n",
        "\n",
        "Fontos, hogy ha több teljes memóriafrissítést végzünk, akkor több választ/válaszsorozatot kapunk.\n"
      ]
    },
    {
      "metadata": {
        "id": "d2ngLz7rlcxe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Eredmények\n",
        "\n",
        "Megjavította a state of the artot\n",
        "\n",
        "- Question Answering-ben (93.3 $\\Rightarrow$ 93,6% a bAbI datasetten)\n",
        "- POS tagging (WSJ PTB: 97,5 $\\Rightarrow$ 97,56%)\n",
        "- Sentiment Analysis (Stanford Sentiment Bank: 87,8 $\\Rightarrow$ 88,6%)"
      ]
    },
    {
      "metadata": {
        "id": "4RBlyw9T3xcy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Az epizodikus memória működése\n",
        "\n",
        "#### Hány menetben érte el a legjobb eredényt a rendszer\n",
        "\n",
        "\n",
        "<img src=\"http://drive.google.com/uc?export=view&id=1SA7GQJ_9_YgLNDBI77buS1LRQP671mVI\" width=\"400px\">"
      ]
    },
    {
      "metadata": {
        "id": "Z2E0hhsZBZBO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Attention vizualizációk\n",
        "\n",
        "<img src=\"http://drive.google.com/uc?export=view&id=1PYjbNHlytpsoL8P3IGw2VIY1rUh0929i\" width=\"800px\">"
      ]
    },
    {
      "metadata": {
        "id": "r_vDGpsIlfK8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Neurális Turing-gépek\n",
        "\n",
        "[Graves et al. (Google DeepMind, 2014): Neural Turing Machines](https://arxiv.org/pdf/1410.5401.pdf)\n",
        "\n",
        "### A kiindulás: a Turing-gép (1937)\n",
        "\n",
        "[Turing (1937): On Computable Numbers](http://l3d.cs.colorado.edu/~ctg/classes/lib/canon/turing-compnum.pdf)\n",
        "\n",
        "\n",
        "<img src=\"http://drive.google.com/uc?export=view&id=1lLi50m3zJSHCcS0gZ3z8SDOx5D-2rWzF\" width=\"500px\">\n",
        "\n",
        "A Turing-gépeket a (végtelen) írható külső memóriájuk teszi lényegesen erősebbé a véges állapotú automatáknál:\n",
        "\n",
        "#### Turing-gép vs FSA különbségek:\n",
        "\n",
        "- A Turing gép írni és olvasni is tudja a külső memóriát, az FSA csak olvas.\n",
        "- A Turing gép feje tetszőleges irányban tud mozogni a szalagon, az FSA sorban, egyirányban olvassa az inputot és nem tud visszafelé haladni.\n",
        "- A Turing gép szalagja végtelen, az FSA inputja és outputja véges.\n",
        "\n",
        "Egy (a kiszámított függvényekre nézve természetesen ekvivalens) Turing-gép variáció input és output szalagokkal:\n",
        "\n",
        "<img src=\"https://www.staff.ncl.ac.uk/joel.wallenberg/ContextsJoelGeoff/lectur14.gif\" width=\"600px\">\n",
        "\n",
        "#### Church-Turing tézis\n",
        "\n",
        "> Ha egy számítási feladat végrehajtható mechanikusan, egy előre megadott algoritmust végrahajtva, akkor megoldható egy Turing-gép segítségével is.\n",
        "\n",
        "#### Kapcsolat a Turing-gépek és neurális hálók között:\n",
        "\n",
        "Mint [Siegelmann and Sontag (1995). On the computational power of neural nets](http://research.cs.queensu.ca/home/akl/cisc879/papers/SELECTED_PAPERS_FROM_VARIOUS_SOURCES/05070215382317071.pdf)\n",
        "kimutatta, tetszőleges Turing gép szimulálható RNN-ekkel."
      ]
    },
    {
      "metadata": {
        "id": "m6D4WGHOM9CY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Alapötlet\n",
        "Próbáljuk meg a fenti architektúrát úgy megvalósítani, hogy a kontroller és az író/olvasó feje(ek) szerepét egy neurális háló játssza!\n",
        "\n",
        "### Architektúra\n",
        "\n",
        "<img src=\"http://drive.google.com/uc?export=view&id=1J9-WcipTgqpQfUMIpcfFwfbctUyzLbvq\" width=\"500px\">\n",
        "\n",
        "Látni fogjuk, hogy a Turing-gépen kívül a modern, CPU-alapú számítőgéparchitektúra is inspirációt jelentett:\n",
        "\n",
        "<img src=\"https://sanjayachauwal.files.wordpress.com/2017/10/overall.gif?w=590&h=345&crop=1\" width=\"500px\">\n",
        "\n",
        "A \"controller\" és az \"író/olvasó\" fejek tulajdonképpen a CPU szerepét játsszák.\n"
      ]
    },
    {
      "metadata": {
        "id": "HU0E0EZZWumg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Alapmodell\n",
        "\n",
        "#### Külső memória (\"Memory Bank\")\n",
        "\n",
        "Egyszerűen egy $N\\times M$ mátrix, ahol\n",
        "\n",
        "- $N$ a memóriahelyek száma\n",
        "- $M$ az egyetlen memóriahelyen tárolható vektor hossza.\n",
        "\n",
        "#### A memória olvasása\n",
        "\n",
        "A MemN2N-hez hasonlóan egy adott $t$ pillanatban egy attention-szerű $\\mathbf{w}_t$ súlyozással olvassuk a memóriát -- a súlyozásokat az olvasófej produkálja.\n",
        "A súlyok normalizáltak, tehát minden $\\mathbf{w}_t(i)$ vektorkoordinátára\n",
        "\n",
        "$$\\mathbf{w}_t(i)\\in [0, 1]$$\n",
        "\n",
        "és\n",
        "\n",
        "$$\\sum_{i=0\\dots N-1} \\mathbf{w}_t(i) = 1$$\n",
        "\n",
        "a kiolvasott memóriatartalom, a $t$ időponthoz tartozó \"read vector\" egyszerűn az összes tárolt vektor súlyozott összege, tehát\n",
        "\n",
        "$$\\mathbf{r}_t = \\sum_{i=0\\dots N-1} \\mathbf{w}_t(i)\\mathbf M_t(i)$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "FaKmQAMFXQVI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### A memória írása\n",
        "\n",
        "Az LSTM-ekhez hasonlóan az írás két fázisban történik, egy _törlés_ és egy _hozzáadás_ operációból áll.\n",
        "Ezeket az írófej a következő paraméterekkel határozza meg:\n",
        "\n",
        "- Az olvasáshoz hasonlóan egy normalizált $\\mathbf{w}_t$ súlyozás\n",
        "- Egy $M$ hosszú $\\mathbf{e}_t$ \"törlésvektor\", ahol minden koordináta $\\in [0, 1]$\n",
        "- Egy $M$ hosszú $\\mathbf{a}_t$ \"hozzáadásvektor\"\n",
        "\n",
        "Maguk a műveletek:\n",
        "\n",
        "- Törlés: $\\hat{\\mathbf M}_t(i) \\leftarrow \\mathbf M_t(i)[\\mathbf 1  - \\mathbf{w}_t(i)\\mathbf e_t]$\n",
        "- Hozzáadás: ${\\mathbf M}_t(i) \\leftarrow \\hat{\\mathbf{M}}_t(i) + \\mathbf{w}_t(i)\\mathbf a_t$\n",
        "\n",
        "Röviden: egy \"elmosódott címzéssel\" (a súlyozással) hajtunk végre a címzett memóriatartalmakon az LSTM \"forget\" és \"update\" műveleteivel analóg műveleteket."
      ]
    },
    {
      "metadata": {
        "id": "f8Hs4A5vkZe4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Címzés: hogyan állnak elő az írási/olvasási súlyozások?\n",
        "\n",
        "Két különböző fajta címzést, illetve ezek kombinációját képes használni a rendszer:\n",
        "\n",
        "##### \"Content-based addressing\"\n",
        "\n",
        "Itt a MemN2N-hez hasonlóan egy hasonlósági mérték szerint súlyozunk:\n",
        "\n",
        "Az írófej produkál egy $M$ hosszú $\\mathbf k_t$ \"kulcsvektort\", ehhez a kulcshoz való hasonlóság szerint súlyozunk, a  $K[\\cdot,\\cdot]$ hasonlósági metrika ás $\\beta_t$ \"kulcserősség\" szerint:\n",
        "\n",
        "$$\\mathbf w_t^c(i)= \\frac{\\exp(\\beta_t K[\\mathbf k_t, \\mathbf M_t(i)])}{\\sum_j \\exp(\\beta_t K[\\mathbf k_t, \\mathbf M_t(j)])}$$\n",
        "\n",
        "Vagyis $\\mathbf w_t$ egy softmax a $\\beta_t K[\\cdot, \\cdot]$ hasonlóságok fölött -- a konkrét implementációban $K$ a koszinusztávolság.\n",
        "\n",
        "##### \"Location-based addressing\"\n",
        "\n",
        "Ez a memóriában előre/hátraugrást valósít meg, tehát egy adott súlyozást \"shiftel\" megadott módon.\n",
        "\n",
        "Konkrétan, az eltolást egy $\\mathbf s_t$ \"shift vektor\" határozza meg, amely egy eloszlás a lehetséges egész shiftek fölött:\n",
        "\n",
        "<img src=\"http://drive.google.com/uc?export=view&id=1-esaoX3CrgPvkMDRi4jGogcdwYeEvCpj\" width=\"700px\">\n"
      ]
    },
    {
      "metadata": {
        "id": "gqHVFQioz3ku",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Mivel az így kapott súlyozás esetleg túl \"életlen\" lehet, ha $\\mathbf s_t$ túl egyenletes, ezért a végső súlyt egy $\\gamma_t > 1$ \"élesítéssel\" kapjuk meg:\n",
        "\n",
        "$$w_t(i) \\leftarrow \\frac{\\tilde{w}_t(i)^{\\gamma_t}}{\\sum_j{\\tilde{w}_t(j)^{\\gamma_t}}}$$ \n",
        "\n",
        "\n",
        "##### A két címzési típus kombinációja\n",
        "A fent leírt eltolási műveletet az adott fej által az aktuális $t$-ben produkált tartalom-alapú súlyozás és a $t-1$ lépésben használt súlyozás egy $g_t \\in (0, 1)$ paraméter szerinti lineáris kombinációjára alkalmazzuk:\n",
        "\n",
        "$$\n",
        "\\mathbf w^g_t = g_t\\mathbf w^c_t + (1-g_t)\\mathbf w_{t-1}\n",
        "$$\n",
        "\n",
        "A címzés teljes működése ennek megfelelően:\n",
        "\n",
        "\n",
        "<img src=\"http://drive.google.com/uc?export=view&id=1J5UXT-k0x25We8DoM69kJY5QU8uLz-sW\" width=\"800px\">\n"
      ]
    },
    {
      "metadata": {
        "id": "2bKfqbQkSQFQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### A teljes rendszer működése \n",
        "\n",
        "<img src=\"http://drive.google.com/uc?export=view&id=1uB1WjSkWzXttN9Dx9riDe_H8Hb7Z-op9\" width=\"400px\">\n",
        "- Mind író, mind olvasó fejből több lehet.\n",
        "- Az írási műveletek (a törlés, ás a hozzáadás) kommutatívak, tehát ha több írófej van a rendszerben, akkor mindegy, milyen sorrendben hajtják végre az egyes fejek ezeket a műveleteket.\n",
        "- A kontroller lehet feedforward vagy RNN háló -- a feedforward kontroller szimulálhatja a rekurrens működést úgy, hogy minden időlépésben olvas és ír egy adott memóriahelyet."
      ]
    },
    {
      "metadata": {
        "id": "mK-IxDbKg_8C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Kísérletek\n",
        "\n",
        "- Három architektúrával:\n",
        "  - NTM + feedforward controller\n",
        "  - NTM + LSTM controller\n",
        "  - LSTM\n",
        "  \n",
        "#### Copy\n",
        "Az input egy random sorozat egy delimiterrel a végén --  a feladat ennek az outputként való visszaadása.\n",
        "\n",
        "A trénelés csak 1--20 hosszúságú sorozatokkal történt, de a NTM-ek (szemben az LSTM)-mel generalizáltak kb. a köv. algoritmust megtanulva:\n",
        "\n",
        "```\n",
        "initialise: move head to start location\n",
        "while input delimiter not seen do\n",
        "  receive input vector\n",
        "  write input to head location\n",
        "  increment head location by 1\n",
        "end while\n",
        "return head to start location\n",
        "while true do\n",
        "  read output vector from head location\n",
        "  emit output\n",
        "  increment head location by 1\n",
        "end while\n",
        "```\n",
        "#### Repeat Copy\n",
        "\n",
        "Az input egy random sorozat és egy ismétlésszám: az outputnak az ismétlésszámszor kell tartalmazni a sorozatot.\n",
        "A sorozathossz generalizációban itt is sokkal jobb volt az MTM, de az ismétlésszámmal problémái voltak\n",
        "\n",
        "#### Associative Recall\n",
        "\n",
        "Az input egy delimitált sorozatokból álló lista, a lista egy random eleme, a rendszernek a lista köv. elemét kell visszaadni.\n",
        "\n",
        "#### Dynamic N-Grams\n",
        "\n",
        "Tud-e n-gram modellt építeni? A feladat az, hogy megjósolja egy (bináris) sorozat folytatását. 200 hosszúságú sorozatok köv. elemét kellett megjósolni.\n",
        "\n",
        "#### Priority sort\n",
        "\n",
        "Input: random vektorsorozat a vektorokhoz rendelt prioritásokkal, a feladat a prioritás szerinti rendezés.\n"
      ]
    },
    {
      "metadata": {
        "id": "vRwkjhxZyGuM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Neural Turing Machine 2.0: Differentiable Neural Computer\n",
        "\n",
        "[Graves et al (Google DeepMind, 2016): Hybrid computing using a neural\n",
        "network with dynamic external memory](https://www.dropbox.com/s/0a40xi702grx3dq/2016-graves.pdf)\n",
        "\n",
        "### Architekturális újítások/változtatások\n",
        "- Egy írófej több olvasófej\n",
        "- Az írófej csak content/kulcs alapú címzést használ\n",
        "- Egy külön mátrix tárolja (simítottan), hogy mely memóriacímek kerültek egymás után írásra\n",
        "- Egy használtsági vektor tárolja, hogy mely memóriacímeket használta már a rendszer\n",
        "- Az olvasás három különböző módon történhet:\n",
        "  - content/kulcs alapon\n",
        "  - a korábbi írási sorrendek szerint előre vagy hátra lépve\n",
        "  - kiválasztva egy üres (kevésbé/régebben használt) memóriahelyet\n",
        "  \n",
        "<img src=\"http://drive.google.com/uc?export=view&id=1HQMkHgWYUL348DT86ZQe371snij1Ui6X\">\n",
        "  \n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "_RYJ78NTXEn6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Alkalmazások/eredmények\n",
        "\n",
        "#### bAbI\n",
        "\n",
        "Mean test error rate 7.5% $\\rightarrow$ 3.8%\n",
        "\n",
        "#### Véletlenszerűen generált gráffeladatok\n",
        "\n",
        "<img src=\"http://drive.google.com/uc?export=view&id=1ckenwxkD75EwfRJSED0O0xi20PtCEMJ3\" width=\"700px\">\n",
        "\n",
        "<img src=\"http://drive.google.com/uc?export=view&id=1wr7CT728KYoVG44P89R5WnVmUVAr5WLC\"  width=\"600px\">\n",
        "\n",
        "#### Objektummozgatás (mini SHRDLU)\n",
        "\n",
        "Itt már a Reinforcement Learning területén járunk...\n"
      ]
    },
    {
      "metadata": {
        "id": "bDo_4qlgGVk8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Természetesen a történetnek nincs vége...\n",
        "\n",
        "- Architekturális újítások, pl.: \n",
        "  - [Dulcehre et al (2017): Dynamic Neural Turing Machine with Soft and Hard Addressing Schemes](https://arxiv.org/pdf/1607.00036.pdf)\n",
        "    (Tanulható memóriacímeket vezet be, plusz SGD helyett a diszkrét attentionös variánsban REINFORCE nevű (vajon honnan származó...) eljárással optimalizál.)\n",
        "- Alkalmazások, különösen Memory Networkökre, pl.\n",
        "  - [Chen et al (2018): Sequential Recommendation with User Memory Networks](http://xu-chen.com/resources/paper-pdf/sequential-rec-memory-network-wsdm18.pdf)\n",
        "  - [Xiong et al (2016: Dynamic Memory Networks for Visual and Textual Question Answering](https://arxiv.org/pdf/1603.01417)"
      ]
    },
    {
      "metadata": {
        "id": "jnaYe8AatYxM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Implementációk\n",
        "\n",
        "- [MemN2N TF-ben](https://github.com/domluna/memn2n)\n",
        "- [Dynamic Memory Networks TF-ben](https://github.com/barronalex/Dynamic-Memory-Networks-in-TensorFlow)\n",
        "- [Differentiable Neural Computer TF-ben a Google-től](https://github.com/deepmind/dnc)"
      ]
    },
    {
      "metadata": {
        "id": "KvFr7af9sAAf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Hogyan kövessük hatékonyan hogy mi folyik AI téren?\n",
        "\n",
        "(Továbbiakban kutatási publikáció = \"paper\" vagy \"papír\").\n",
        "\n",
        "## Probléma 1.: Össz mennyiség / sebesség\n",
        "\n",
        "<img src=\"https://thumbor.forbes.com/thumbor/960x0/https%3A%2F%2Fblogs-images.forbes.com%2Flouiscolumbus%2Ffiles%2F2018%2F01%2Fannually-published-papers.jpg\">\n",
        "\n",
        "Bővebben [itt](https://www.forbes.com/sites/louiscolumbus/2018/01/12/10-charts-that-will-change-your-perspective-on-artificial-intelligences-growth/#384b45647583)\n",
        "\n",
        "### Ráadásul Open Science\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a8/ArXiv_web.svg/500px-ArXiv_web.svg.png\">\n",
        "\n",
        "**A Forrás: [arXiv](https://arxiv.org/)** \n",
        "\n",
        "## Megoldás: Használj szűrőt!\n",
        "\n",
        "### [Arxiv Sanity preserver]()\n",
        "\n",
        "Személyre szabott recommender engine az ArXiv böngészéséhez. (AI-kereső-AI-kereső-AI... :-P\n",
        "\n",
        "\n",
        "<img src=\"https://camo.githubusercontent.com/cd467093cba639a7fc914e369f47ecad0ca16ded/68747470733a2f2f7261772e6769746875622e636f6d2f6b617270617468792f61727869762d73616e6974792d7072657365727665722f6d61737465722f75692e6a706567\">\n",
        "\n",
        "\n",
        "Bemutató [itt](https://www.youtube.com/watch?v=S2GY3gh6qC8&feature=youtu.be)\n",
        "\n",
        "\n",
        "### Közösség, mint szűrő\n",
        "\n",
        "- Kövess influencer-eket Twitteren, Facebookon vagy LinkedIn-en\n",
        "  - Vagy \"nagy\" név alapján (Hinton, LeCun, Bengio, Ng, Schmidhuber, Hochreiter, Sutskever, Goodfellow, Larochelle, Karpathy, ... ...)\n",
        "  - Akinek a cikkét olvastad és értékesnek találtad\n",
        "  - Vagy listából (nem olyan jók, cserébe van sok :-)\n",
        "- \"[A Facebook csoport\"](https://www.facebook.com/groups/DeepNetGroup/) (137k members and counting...) \n",
        "\n",
        "## Probléma 2.: Egységnyi papír komplexitása\n",
        "\n",
        "<img src=\"https://cdn-images-1.medium.com/max/1400/1*OlOpTJNL3Zyf6MOaZO05lw.jpeg\">\n",
        "\n",
        "## Megoldás: Olvasási stratégia (Szubjektív javaslat)\n",
        "\n",
        "Jó megközelítés a komplex AI papírok olvasásához [itt](https://medium.com/ai-saturdays/how-to-read-academic-papers-without-freaking-out-3f7ef43a070f).\n",
        "\n",
        "<img src=\"https://askabiologist.asu.edu/sites/default/files/resources/articles/anatomy_of_an_article/anatomy_paper_diagram3.jpg\">\n",
        "\n",
        "** I. \"A buszon\" **\n",
        "1. Olvasd el a címet (ha nem érdekes, stop)\n",
        "2. Olvasd el az abstractot (ha nem érdekes, stop)\n",
        "3. Lapozz a Result részhez, keresd és értelmezd a táblázatos eredményeket (ha nem érdekes, stop)\n",
        "4. Gyűjtsd olvasólistába.\n",
        "\n",
        "** II. \"Amikor van időd\" **\n",
        "5. Frissítsd fel az abstract és results részt\n",
        "6. Olvasd át és próbáld megérteni a methods részt\n",
        "  - Mit nem ír le, mit nem értesz?\n",
        "  - Mi a \"common assumption\"?\n",
        "7. Tárd fel a \"common assumption\" elemeket a referencia jegyzék segítségevel. (Kövesd vissza \"A Nagy Papírokig\")\n",
        "8. Jegyzetelj\n",
        "9. Nézd meg a konferencia vagy az adott előadó videóját! (Ha van...)\n",
        "10. Keress implementációt\n",
        "11. Kezdd újra az 6.-tól amíg jó nem lesz!\n"
      ]
    }
  ]
}
